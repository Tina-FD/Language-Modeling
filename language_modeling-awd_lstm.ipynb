{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["VrFCH9hpEyip","UcNIGF4CUCk3","AFHw176FhqQa","uWoVZ_MuKif0","t6tRkdc5HoZT","BNJRZe4QBudV","RwaY_YcgRayy","pwlVLNJXfUJw","3in1e9BksgIh","RTql4Ftiunfr","ujIVtjsYvxOI","wCi-ofSLCzop","idRexFij4wgN","PgLgP04P4-aX","NCQjacybOfqV","3ttl0AK3Hvyh","24qT-sgUO2-d","W0QNbC0YPCKZ","G9HgVWslPGsH","o_5f69nwPtY2","De7VreNxQdct","lpJ3wtyctQJH","BrHQCv7q7LF_","BLT4w0ZfAhlJ","uC2GhaXfA8vC","Mjd9Z3N1ef3I","rjGQ-M02cusP","oK20iNRI3Xxb","KZ9UIdmkfxlA","FzcQQwFuar_7"],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#  <font color='#FFE15D'><b>Language Modeling</b></font>"],"metadata":{"id":"-uXkcYhkIxS-"}},{"cell_type":"markdown","source":["# üî¥ **Environment Setup**"],"metadata":{"id":"VrFCH9hpEyip"}},{"cell_type":"code","source":["!pip install -q torch==2.3.0 torchtext==0.18.0 torchmetrics portalocker>=2.0.0"],"metadata":{"id":"LNviCLHzd79w","executionInfo":{"status":"ok","timestamp":1726602262435,"user_tz":-210,"elapsed":3824,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["!pip install -q wandb"],"metadata":{"id":"nbX6I2IJHoZV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726602277549,"user_tz":-210,"elapsed":6038,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}},"outputId":"50f821ae-880c-45db-c5e8-d2241efd15ae"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m311.4/311.4 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"markdown","source":["# üî¥ **Import Libs**"],"metadata":{"id":"BNJRZe4QBudV"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torchtext\n","from torchtext.datasets import WikiText2\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator, GloVe\n","\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader, Dataset, random_split\n","\n","from torch import optim\n","from torch.nn import functional as F\n","\n","import tqdm\n","import torchmetrics as tm\n","import wandb\n","\n","import os\n","from collections import Counter\n","\n","import ipywidgets as widgets\n","from IPython.display import display"],"metadata":{"id":"vhlVJEkJeTsV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python --version"],"metadata":{"id":"DEzYlyeqTZqQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726602331451,"user_tz":-210,"elapsed":6,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}},"outputId":"4213978b-7e62-4ed3-956e-2cd0d0a246cb"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Python 3.10.12\n"]}]},{"cell_type":"code","source":["for lib in [np, torch, torchtext, tqdm]:\n","  print(lib.__name__, '-->', lib.__version__)"],"metadata":{"id":"6DWjGTq6T8Jg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726602333910,"user_tz":-210,"elapsed":8,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}},"outputId":"781fa6dd-bf38-4778-e88f-15f3140274d2"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["numpy --> 1.26.4\n","torch --> 2.3.0+cu121\n","torchtext --> 0.18.0+cpu\n","tqdm --> 4.66.5\n"]}]},{"cell_type":"markdown","source":["# üî¥ **Utils**"],"metadata":{"id":"RwaY_YcgRayy"}},{"cell_type":"code","source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"],"metadata":{"id":"8yMS7bbmRayz","executionInfo":{"status":"ok","timestamp":1726602338656,"user_tz":-210,"elapsed":649,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def num_trainable_params(model):\n","  nums = sum(p.numel() for p in model.parameters() if p.requires_grad)/1e6\n","  return nums"],"metadata":{"id":"PpKbTUEIRayz","executionInfo":{"status":"ok","timestamp":1726602341276,"user_tz":-210,"elapsed":2,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def set_seed(seed):\n","  np.random.seed(seed)\n","  torch.manual_seed(seed)\n","  if torch.cuda.is_available():\n","      torch.cuda.manual_seed(seed)"],"metadata":{"id":"6w6sLRLfw398","executionInfo":{"status":"ok","timestamp":1726602351512,"user_tz":-210,"elapsed":833,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["# üî¥ **Arguments**"],"metadata":{"id":"pwlVLNJXfUJw"}},{"cell_type":"code","source":["seed = 8\n","\n","batch_size = 80\n","seq_len = 70\n","\n","embedding_dim = 300\n","\n","num_layers = 3\n","hidden_dim = 1150\n","dropoute = 0.1\n","dropouti = 0.65\n","dropouth = 0.3\n","dropouto = 0.4\n","weight_drop = 0.5\n","\n","lr = 30\n","wd = 1.2e-6\n","momentum = 0\n","\n","clip = 0.25\n","\n","wandb_enable = True"],"metadata":{"id":"BqPVGv0TfUKE","executionInfo":{"status":"ok","timestamp":1726602513721,"user_tz":-210,"elapsed":824,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["wandb_arg_name = input('Please input the WandB argument (run) name:')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SXOG_oXwrICX","executionInfo":{"status":"ok","timestamp":1726602529518,"user_tz":-210,"elapsed":11572,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}},"outputId":"5878edb3-ec64-4cf2-8ea2-2194af672124"},"execution_count":10,"outputs":[{"name":"stdout","output_type":"stream","text":["Please input the WandB argument (run) name:weight_drop\n"]}]},{"cell_type":"code","source":["wandb_arg_name"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Vp5AUcSs-drV","executionInfo":{"status":"ok","timestamp":1726602532370,"user_tz":-210,"elapsed":677,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}},"outputId":"ea397ad7-f667-4f2a-fa1e-2cd598a50249"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'weight_drop'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["# üî¥ **Dataset**"],"metadata":{"id":"RTql4Ftiunfr"}},{"cell_type":"markdown","source":["## üü† Load the Dataset"],"metadata":{"id":"ujIVtjsYvxOI"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0T0bMKWziGBp","executionInfo":{"status":"ok","timestamp":1726602604272,"user_tz":-210,"elapsed":33495,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}},"outputId":"f987b1dd-6fb5-40d8-bab7-6a4c6e409acd"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["! cp -r /content/drive/MyDrive/Deep_learning_projects/1_language_modeling/wikitext-2 /content/"],"metadata":{"id":"ocTwDktGiOxv","executionInfo":{"status":"ok","timestamp":1726602697818,"user_tz":-210,"elapsed":5966,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["## üü† Build vocabulary and save it"],"metadata":{"id":"wCi-ofSLCzop"}},{"cell_type":"code","source":["def load_dataset(path):\n","  with open(path) as f :\n","    dataset = f.read()\n","  return dataset\n","\n","def tokenize_dataset(dataset):\n","  tokens = []\n","  for line in dataset.split('\\n'):\n","    tokens.extend(tokenizer(line.strip()))\n","  return tokens"],"metadata":{"id":"yv4GTShuintA","executionInfo":{"status":"ok","timestamp":1726602716478,"user_tz":-210,"elapsed":624,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["tokenizer = get_tokenizer(\"basic_english\")"],"metadata":{"id":"eTI0zvuFinkJ","executionInfo":{"status":"ok","timestamp":1726602746960,"user_tz":-210,"elapsed":749,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["train_dataset = load_dataset(\"/content/wikitext-2/wiki.train.tokens\")\n","valid_dataset = load_dataset(\"/content/wikitext-2/wiki.valid.tokens\")\n","test_dataset = load_dataset(\"/content/wikitext-2/wiki.test.tokens\")\n","\n","train_tokens = tokenize_dataset(train_dataset)\n","valid_tokens = tokenize_dataset(valid_dataset)\n","test_tokens = tokenize_dataset(test_dataset)\n","\n","all_tokens = train_tokens + valid_tokens + test_tokens\n","print(\"Train Tokens: \" , len(train_tokens))\n","print(\"Valid Tokens: \" , len(valid_tokens))\n","print(\"Test Tokens: \" , len(test_tokens))\n","print(\"Total number of tokens:\", len(all_tokens))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ruLjFYqciwma","executionInfo":{"status":"ok","timestamp":1726602749542,"user_tz":-210,"elapsed":1957,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}},"outputId":"c79081fc-8f20-4f40-c4f2-511a5e2eedfc"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Train Tokens:  2049990\n","Valid Tokens:  214417\n","Test Tokens:  241859\n","Total number of tokens: 2506266\n"]}]},{"cell_type":"code","source":["tokenized_datasets = [train_tokens]\n","\n","special_tokens = ['<unk>']\n","\n","vocab = build_vocab_from_iterator(tokenized_datasets, specials=special_tokens)\n","\n","vocab.set_default_index(vocab['<unk>'])\n","\n","vocab_size = len(vocab)\n","\n","torch.save(vocab, \"./Wikitext_train_vocab.pt\")\n","print(\"Vocabulary size:\", vocab_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3WcinmaRi0U8","executionInfo":{"status":"ok","timestamp":1726602761152,"user_tz":-210,"elapsed":794,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}},"outputId":"05bd5fc9-ed4a-42c3-e4ed-2df1a427f7e2"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabulary size: 28782\n"]}]},{"cell_type":"markdown","source":["## üü† Transform the data"],"metadata":{"id":"idRexFij4wgN"}},{"cell_type":"code","source":["def data_process(raw_text_iter, seq_len):\n","  data = torch.cat([torch.LongTensor(vocab(tokenize_dataset(line))) for line in raw_text_iter.split(\"\\n\")])\n","\n","  M = len(data) // seq_len\n","\n","  r = len(data) % seq_len\n","  data = torch.cat((data, torch.LongTensor([0]))) if r==0 else data\n","\n","  inputs = data[:M*seq_len]\n","  inputs = inputs.reshape(-1, seq_len)\n","\n","  targets = data[1:M*seq_len+1]\n","  targets = targets.reshape(-1, seq_len)\n","\n","  return inputs, targets"],"metadata":{"id":"ocxM8YdsWH-1","executionInfo":{"status":"ok","timestamp":1726602788209,"user_tz":-210,"elapsed":1073,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["X_train ,y_train =data_process(train_dataset, seq_len)\n","X_valid ,y_valid =data_process(valid_dataset, seq_len)\n","X_test ,y_test =data_process(test_dataset, seq_len)\n","\n","X_train.shape ,y_train.shape, X_valid.shape, y_valid.shape, X_test.shape, y_test.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y1Am95DPRUOo","executionInfo":{"status":"ok","timestamp":1726602809394,"user_tz":-210,"elapsed":3814,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}},"outputId":"40547d32-1cd1-478a-d270-01093a662fcc"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([29285, 70]),\n"," torch.Size([29285, 70]),\n"," torch.Size([3063, 70]),\n"," torch.Size([3063, 70]),\n"," torch.Size([3455, 70]),\n"," torch.Size([3455, 70]))"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","source":["## üü† Custom dataset"],"metadata":{"id":"PgLgP04P4-aX"}},{"cell_type":"markdown","source":["üî∞ Write a custom dataset class for LanguageModelDataset."],"metadata":{"id":"XkxH_IR2PBNq"}},{"cell_type":"code","source":["class LanguageModelDataset(Dataset):\n","\n","  def __init__(self, inputs, targets):\n","    self.inputs = inputs\n","    self.targets = targets\n","\n","  def __len__(self):\n","    return self.inputs.shape[0]\n","\n","  def __getitem__(self, idx):\n","    return self.inputs[idx], self.targets[idx]"],"metadata":{"id":"1cjpSkrtexap","executionInfo":{"status":"ok","timestamp":1726602814311,"user_tz":-210,"elapsed":743,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["train_set = LanguageModelDataset(X_train, y_train)\n","valid_set = LanguageModelDataset(X_valid, y_valid)\n","test_set = LanguageModelDataset(X_test, y_test)"],"metadata":{"id":"o0qUkL0CfQmr","executionInfo":{"status":"ok","timestamp":1726602817059,"user_tz":-210,"elapsed":2,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":["## üü† Define a dataloader if needed"],"metadata":{"id":"NCQjacybOfqV"}},{"cell_type":"markdown","source":["üî∞ Write dataloaders for the training, validation, and test sets."],"metadata":{"id":"HqKMEyFNS-1a"}},{"cell_type":"code","source":["set_seed(seed)\n","\n","train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n","valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False)\n","test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"],"metadata":{"id":"KMCJ3UMD0U_f","executionInfo":{"status":"ok","timestamp":1726602823219,"user_tz":-210,"elapsed":640,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["x_batch, y_batch = next(iter(train_loader))\n","x_batch.shape, y_batch.shape, x_batch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_lRY0FnUTDEN","executionInfo":{"status":"ok","timestamp":1726602827845,"user_tz":-210,"elapsed":3,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}},"outputId":"8f4e3d58-61f8-417c-ceff-e74eb0ff563f"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([80, 70]),\n"," torch.Size([80, 70]),\n"," tensor([[ 1985,    13,     1,  ...,  1985,    13,     1],\n","         [  104,     2,    57,  ..., 16138,  2285,    92],\n","         [    2,    22,   100,  ...,   116,    22,     2],\n","         ...,\n","         [   22,     0,   173,  ...,    37, 12908,     6],\n","         [    6,    43,  8400,  ...,    93,     3,     1],\n","         [25828,    65,    46,  ...,     3,   179,  1108]]))"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["set_seed(seed)\n","\n","for inputs, targets in train_loader:\n","  print(inputs[0, 0], targets[0, 0])\n","  break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HVoUEQm1yhNi","executionInfo":{"status":"ok","timestamp":1726602839112,"user_tz":-210,"elapsed":1027,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}},"outputId":"441636ed-e906-44cb-98ac-b1ae509080dd"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(1985) tensor(13)\n"]}]},{"cell_type":"markdown","source":["# üî¥ **Model**"],"metadata":{"id":"3ttl0AK3Hvyh"}},{"cell_type":"code","source":["class WeightDrop(torch.nn.Module):\n","\n","  def __init__(self, module, weights, dropout=0):\n","    super(WeightDrop, self).__init__()\n","    self.module = module\n","    self.weights = weights\n","    self.dropout = dropout\n","    self._setup()\n","\n","  def widget_demagnetizer_y2k_edition(*args, **kwargs):\n","    return\n","\n","  def _setup(self):\n","    if issubclass(type(self.module), torch.nn.RNNBase):\n","      self.module.flatten_parameters = self.widget_demagnetizer_y2k_edition\n","\n","      for name_w in self.weights:\n","        print('Applying weight drop of {} to {}'.format(self.dropout, name_w))\n","        w = getattr(self.module, name_w)\n","        del self.module._parameters[name_w]\n","        self.module.register_parameter(name_w + '_raw', nn.Parameter(w.data))\n","\n","  def _setweights(self):\n","    for name_w in self.weights:\n","      raw_w = getattr(self.module, name_w + '_raw')\n","      w = None\n","      # w = torch.nn.functional.dropout(raw_w, p=self.dropout, training=self.training)\n","      mask = torch.nn.functional.dropout(torch.ones_like(raw_w), p=self.dropout, training=True) * (1 - self.dropout)\n","      setattr(self.module, name_w, raw_w * mask)\n","\n","  def forward(self, *args):\n","    self._setweights()\n","    return self.module.forward(*args)"],"metadata":{"id":"bWDUTrsIzRhr","executionInfo":{"status":"ok","timestamp":1726602844275,"user_tz":-210,"elapsed":635,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["def embedded_dropout(embed, words, dropout=0.1, scale=None):\n","  if dropout:\n","    mask = embed.weight.data.new().resize_((embed.weight.size(0), 1)).bernoulli_(1 - dropout).expand_as(\n","        embed.weight) / (1 - dropout)\n","    masked_embed_weight = mask * embed.weight\n","  else:\n","    masked_embed_weight = embed.weight\n","  if scale:\n","    masked_embed_weight = scale.expand_as(masked_embed_weight) * masked_embed_weight\n","\n","  padding_idx = embed.padding_idx\n","  if padding_idx is None:\n","    padding_idx = -1\n","\n","  embedding = torch.nn.functional.embedding(words, masked_embed_weight,\n","                                            padding_idx, embed.max_norm, embed.norm_type,\n","                                            embed.scale_grad_by_freq, embed.sparse)\n","  return embedding"],"metadata":{"id":"Z2rOXE6mNe68","executionInfo":{"status":"ok","timestamp":1726602847751,"user_tz":-210,"elapsed":1317,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["class LockedDropout(nn.Module):\n","  def __init__(self):\n","    super(LockedDropout, self).__init__()\n","\n","  def forward(self, x, dropout):\n","    if not self.training or not dropout:\n","      return x\n","    m = x.data.new(1, x.size(1), x.size(2)).bernoulli_(1 - dropout)\n","    mask = m.requires_grad_(False) / (1 - dropout)\n","    mask = mask.expand_as(x)\n","    return mask * x"],"metadata":{"id":"CwBQ3I-XLIHw","executionInfo":{"status":"ok","timestamp":1726602850034,"user_tz":-210,"elapsed":1,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["üî∞ AWD-LSTM Language Model"],"metadata":{"id":"baOLnaB8jVC-"}},{"cell_type":"code","source":["class LanguageModel(nn.Module):\n","\n","  def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers,\n","               dropoute=0.2, dropouti=0.2, dropouth=0.2, dropouto=0.2,\n","               weight_drop=0.2):\n","    super().__init__()\n","    self.num_layers = num_layers\n","    self.hidden_dim = hidden_dim\n","    self.embedding_dim = embedding_dim\n","\n","    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","    self.embedding.weight.data.uniform_(-0.1, 0.1)\n","\n","    self.lstms = []\n","    self.lstms.append(nn.LSTM(embedding_dim, hidden_dim, num_layers=1, dropout=0, batch_first=False))\n","    self.lstms.append(nn.LSTM(hidden_dim, hidden_dim, num_layers=1, dropout=0, batch_first=False))\n","    self.lstms.append(nn.LSTM(hidden_dim, embedding_dim, num_layers=1, dropout=0, batch_first=False))\n","    if weight_drop > 0:\n","      self.lstms = [WeightDrop(lstm, ['weight_hh_l0'], dropout=weight_drop) for lstm in self.lstms]\n","    self.lstms = nn.ModuleList(self.lstms)\n","\n","    self.fc = nn.Linear(embedding_dim, vocab_size)\n","\n","    self.fc.weight = self.embedding.weight\n","\n","    self.lockdrop = LockedDropout()\n","    self.dropoute = dropoute\n","    self.dropouti = dropouti\n","    self.dropouth = dropouth\n","    self.dropouto = dropouto\n","    # print(dropoute, dropouti, dropouth, dropouto)\n","\n","  def forward(self, src):\n","    embedding = embedded_dropout(self.embedding, src, dropout=self.dropoute if self.training else 0)\n","    embedding = self.lockdrop(embedding, self.dropouti)\n","\n","    new_hiddens = []\n","    for l, lstm in enumerate(self.lstms):\n","      embedding, _ = lstm(embedding)\n","      if l != self.num_layers-1:\n","        embedding = self.lockdrop(embedding, self.dropouth)\n","\n","    embedding = self.lockdrop(embedding, self.dropouto)\n","\n","    prediction = self.fc(embedding)\n","    return prediction"],"metadata":{"id":"ISnnHE0BMVqp","executionInfo":{"status":"ok","timestamp":1726602852382,"user_tz":-210,"elapsed":2,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":["# üî¥ **Config**"],"metadata":{"id":"24qT-sgUO2-d"}},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device"],"metadata":{"id":"Ma28M5Z36gsq","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1726602882968,"user_tz":-210,"elapsed":1018,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}},"outputId":"4178cc5a-f883-4a26-ae95-5171167e2fef"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cuda'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["loss_fn = nn.CrossEntropyLoss()\n","\n","metric = tm.text.Perplexity().to(device)"],"metadata":{"id":"9ubk3xKaIG6i","executionInfo":{"status":"ok","timestamp":1726602886188,"user_tz":-210,"elapsed":640,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["key_file = '/content/key.txt'\n","\n","if os.path.exists(key_file):\n","    with open(key_file) as f:\n","        key = f.readline().strip()\n","    wandb.login(key=key)\n","else:\n","    print(\"Key file does not exist. Please create the key file with your wandb API key.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5znK6USrlVd5","executionInfo":{"status":"ok","timestamp":1726603236922,"user_tz":-210,"elapsed":990,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}},"outputId":"95e6417c-f492-425a-efdf-651e7e27eda1"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}]},{"cell_type":"markdown","source":["# üî¥ **Train ‚û∞**"],"metadata":{"id":"W0QNbC0YPCKZ"}},{"cell_type":"code","source":["def train_one_epoch(model, train_loader, loss_fn, optimizer, metric, epoch=None):\n","  model.train()\n","  loss_train = AverageMeter()\n","  metric.reset()\n","\n","  with tqdm.tqdm(train_loader, unit='batch') as tepoch:\n","    for inputs, targets in tepoch:\n","      if epoch:\n","        tepoch.set_description(f'Epoch {epoch}')\n","\n","      inputs = inputs.t().to(device)\n","      targets = targets.t().to(device)\n","\n","      outputs = model(inputs)\n","\n","      loss = loss_fn(outputs.reshape(-1, outputs.shape[-1]), targets.flatten())\n","\n","      loss.backward()\n","\n","      nn.utils.clip_grad.clip_grad_norm_(model.parameters(), max_norm=clip)\n","\n","      optimizer.step()\n","      optimizer.zero_grad()\n","\n","      loss_train.update(loss.item(), n=len(targets))\n","      metric.update(outputs, targets)\n","\n","      tepoch.set_postfix(loss=loss_train.avg, metric=metric.compute().item())\n","\n","  return model, loss_train.avg, metric.compute().item()"],"metadata":{"id":"WniOAgk0QyRI","executionInfo":{"status":"ok","timestamp":1726603266489,"user_tz":-210,"elapsed":1040,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}}},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":["# üî¥ **Evaluation**"],"metadata":{"id":"G9HgVWslPGsH"}},{"cell_type":"markdown","source":["üî∞ This is the template for evaluation function, change it if needed."],"metadata":{"id":"TsszJ7GVj2l3"}},{"cell_type":"code","source":["def evaluate(model, test_loader, loss_fn, metric):\n","  model.eval()\n","  loss_eval = AverageMeter()\n","  metric.reset()\n","\n","  with torch.inference_mode():\n","    for inputs, targets in test_loader:\n","      inputs = inputs.t().to(device)\n","      targets = targets.t().to(device)\n","\n","      outputs = model(inputs)\n","\n","      loss = loss_fn(outputs.reshape(-1, outputs.shape[-1]), targets.flatten())\n","      loss_eval.update(loss.item(), n=len(targets))\n","\n","      metric(outputs, targets)\n","\n","  return loss_eval.avg, metric.compute().item()"],"metadata":{"id":"uV0_67_ZQ0xf","executionInfo":{"status":"ok","timestamp":1726603270582,"user_tz":-210,"elapsed":868,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}}},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":["# üî¥ **Training Process „ÄΩÔ∏è**"],"metadata":{"id":"o_5f69nwPtY2"}},{"cell_type":"markdown","source":["## üü† Finding Hyper-parameters"],"metadata":{"id":"De7VreNxQdct"}},{"cell_type":"markdown","source":["### üü° **Step 1:** Calculate the loss for an untrained model using a few batches.\n"],"metadata":{"id":"lpJ3wtyctQJH"}},{"cell_type":"code","source":["model = LanguageModel(len(vocab), embedding_dim=300,\n","                      hidden_dim=512, num_layers=2,\n","                      dropout_embd=0.5, dropout_rnn=0.2).to(device)\n","\n","inputs, targets = next(iter(train_loader))\n","inputs = inputs.to(device)\n","targets = targets.to(device)\n","\n","with torch.no_grad():\n","  outputs = model(inputs)\n","  loss = loss_fn(outputs.reshape(-1, outputs.shape[-1]), targets.flatten())\n","\n","print(loss)"],"metadata":{"id":"QnE4F4GkzzaR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["outputs.reshape(-1, outputs.shape[-1]).shape, targets.flatten().shape"],"metadata":{"id":"pxHX7YRCBVxM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"XHj-Mp8FA_DW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### üü° **Step 2:** Try to train and overfit the model on a small subset of the dataset."],"metadata":{"id":"BrHQCv7q7LF_"}},{"cell_type":"code","source":["model = LanguageModel(len(vocab), embedding_dim=embedding_dim,\n","                      hidden_dim=hidden_dim, num_layers=num_layers,\n","                      dropout_embd=dropout_embd, dropout_rnn=dropout_rnn).to(device)\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.9, momentum=0.9)"],"metadata":{"id":"G0ji0MXsWaPt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mini_train_size = 1000\n","_, mini_train_dataset = random_split(train_set, (len(train_set)-mini_train_size, mini_train_size))\n","mini_train_loader = DataLoader(mini_train_dataset, 20)"],"metadata":{"id":"kPRZQpPWJ2qv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_epochs = 100\n","for epoch in range(num_epochs):\n","  model, _, _ = train_one_epoch(model, mini_train_loader, loss_fn, optimizer, metric, epoch)"],"metadata":{"id":"6FNIFCM6A6al"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### üü° **Step 3:** Train the model for a limited number of epochs, experimenting with various learning rates."],"metadata":{"id":"BLT4w0ZfAhlJ"}},{"cell_type":"code","source":["num_epochs = 1\n","\n","for lr in [20, 15, 10, 7.5, 5, 2.5]:\n","  print(f'LR={lr}')\n","\n","  model = LanguageModel(vocab_size=len(vocab), embedding_dim=embedding_dim,\n","                      hidden_dim=hidden_dim, num_layers=num_layers,\n","                      dropoute=dropoute, dropouti=dropouti,\n","                      dropouth=dropouth, dropouto=dropouto,\n","                      weight_drop=weight_drop, pretrained=True).to(device)\n","  # model = torch.load('model.pt')\n","\n","  optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=momentum)\n","\n","  for epoch in range(num_epochs):\n","    model, _, _ = train_one_epoch(model, train_loader, loss_fn, optimizer, metric, epoch)\n","\n","  print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"AqFqm1smGVrX","executionInfo":{"status":"error","timestamp":1696019876374,"user_tz":-210,"elapsed":446002,"user":{"displayName":"Howsam AI","userId":"14680048223925681202"}},"outputId":"49004e92-4b8d-4a53-97fb-8b5731b5a868"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["LR=20\n",".\n","Applying weight drop of 0.5 to weight_hh_l0\n","Applying weight drop of 0.5 to weight_hh_l0\n","Applying weight drop of 0.5 to weight_hh_l0\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|                                                                                       | 0/367 [00:00<?, ?batch/s]C:\\Users\\PC\\anaconda3\\envs\\howsam-deep\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:769: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:968.)\n","  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n","100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 367/367 [01:31<00:00,  4.02batch/s, loss=8.88, metric=7.16e+3]\n"]},{"output_type":"stream","name":"stdout","text":["\n","LR=15\n",".\n","Applying weight drop of 0.5 to weight_hh_l0\n","Applying weight drop of 0.5 to weight_hh_l0\n","Applying weight drop of 0.5 to weight_hh_l0\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 367/367 [01:26<00:00,  4.24batch/s, loss=6.75, metric=857]\n"]},{"output_type":"stream","name":"stdout","text":["\n","LR=10\n",".\n","Applying weight drop of 0.5 to weight_hh_l0\n","Applying weight drop of 0.5 to weight_hh_l0\n","Applying weight drop of 0.5 to weight_hh_l0\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 367/367 [01:20<00:00,  4.56batch/s, loss=6.75, metric=858]\n"]},{"output_type":"stream","name":"stdout","text":["\n","LR=7.5\n",".\n","Applying weight drop of 0.5 to weight_hh_l0\n","Applying weight drop of 0.5 to weight_hh_l0\n","Applying weight drop of 0.5 to weight_hh_l0\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 367/367 [01:28<00:00,  4.16batch/s, loss=6.79, metric=894]\n"]},{"output_type":"stream","name":"stdout","text":["\n","LR=5\n",".\n","Applying weight drop of 0.5 to weight_hh_l0\n","Applying weight drop of 0.5 to weight_hh_l0\n","Applying weight drop of 0.5 to weight_hh_l0\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 367/367 [01:28<00:00,  4.16batch/s, loss=6.84, metric=939]\n"]},{"output_type":"stream","name":"stdout","text":["\n","LR=2.5\n",".\n","Applying weight drop of 0.5 to weight_hh_l0\n","Applying weight drop of 0.5 to weight_hh_l0\n","Applying weight drop of 0.5 to weight_hh_l0\n"]},{"output_type":"stream","name":"stderr","text":["  2%|‚ñâ                                                   | 7/367 [00:01<01:40,  3.59batch/s, loss=9.56, metric=1.42e+4]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Input \u001b[1;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr, weight_decay\u001b[38;5;241m=\u001b[39mwd, momentum\u001b[38;5;241m=\u001b[39mmomentum)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m---> 16\u001b[0m   model, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n","Input \u001b[1;32mIn [38]\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, train_loader, loss_fn, optimizer, metric, epoch)\u001b[0m\n\u001b[0;32m     14\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[0;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, outputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]), targets\u001b[38;5;241m.\u001b[39mflatten())\n\u001b[1;32m---> 18\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m nn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39mclip)\n\u001b[0;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n","File \u001b[1;32m~\\anaconda3\\envs\\howsam-deep\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32m~\\anaconda3\\envs\\howsam-deep\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["### üü° Step 4: Create a small grid using the weight decay and the best learning rate.\n","\n","\n","\n"],"metadata":{"id":"uC2GhaXfA8vC"}},{"cell_type":"code","source":["num_epochs = 1\n","\n","for lr in [7, 8, 14, 13, 12, 11, 10, 9]:\n","  for wd in [1.2e-6]:\n","    print(f'LR={lr}, WD={wd}')\n","\n","    model = LanguageModel(vocab_size=len(vocab), embedding_dim=embedding_dim,\n","                      hidden_dim=hidden_dim, num_layers=num_layers,\n","                      dropoute=dropoute, dropouti=dropouti,\n","                      dropouth=dropouth, dropouto=dropouto,\n","                      weight_drop=weight_drop, pretrained=True).to(device)\n","\n","    optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=0.9)\n","\n","    for epoch in range(num_epochs):\n","      model, _, _ = train_one_epoch(model, train_loader, loss_fn, optimizer, metric, epoch)\n","\n","    print()"],"metadata":{"id":"a7UeNW3WWaPu","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1696016502061,"user_tz":-210,"elapsed":184783,"user":{"displayName":"Howsam AI","userId":"14680048223925681202"}},"outputId":"e51f3f4b-776d-4dc1-82d3-52aad3af3a7e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["LR=7, WD=1.2e-06\n",".\n","Applying weight drop of 0.5 to weight_hh_l0\n","Applying weight drop of 0.5 to weight_hh_l0\n","Applying weight drop of 0.5 to weight_hh_l0\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 367/367 [01:28<00:00,  4.15batch/s, loss=6.68, metric=795]\n"]},{"output_type":"stream","name":"stdout","text":["\n","LR=8, WD=1.2e-06\n",".\n","Applying weight drop of 0.5 to weight_hh_l0\n","Applying weight drop of 0.5 to weight_hh_l0\n","Applying weight drop of 0.5 to weight_hh_l0\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 367/367 [01:29<00:00,  4.11batch/s, loss=6.61, metric=745]\n"]},{"output_type":"stream","name":"stdout","text":["\n","LR=14, WD=1.2e-06\n",".\n","Applying weight drop of 0.5 to weight_hh_l0\n","Applying weight drop of 0.5 to weight_hh_l0\n","Applying weight drop of 0.5 to weight_hh_l0\n"]},{"output_type":"stream","name":"stderr","text":["  3%|‚ñà‚ñå                                                 | 11/367 [00:02<01:32,  3.83batch/s, loss=11.3, metric=8.28e+4]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr, weight_decay\u001b[38;5;241m=\u001b[39mwd, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m---> 16\u001b[0m   model, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n","Input \u001b[1;32mIn [29]\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, train_loader, loss_fn, optimizer, metric, epoch)\u001b[0m\n\u001b[0;32m     14\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[0;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, outputs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]), targets\u001b[38;5;241m.\u001b[39mflatten())\n\u001b[1;32m---> 18\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m nn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39mclip)\n\u001b[0;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n","File \u001b[1;32m~\\anaconda3\\envs\\howsam-deep\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32m~\\anaconda3\\envs\\howsam-deep\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["### üü° Step 5: Train model for longer epochs using the best model from step 4.\n","\n","\n","\n"],"metadata":{"id":"Mjd9Z3N1ef3I"}},{"cell_type":"code","source":["model = LanguageModel(len(vocab), embedding_dim=300,\n","                      hidden_dim=512, num_layers=2,\n","                      dropout_embd=0.5, dropout_rnn=0.2).to(device)"],"metadata":{"id":"IWgkMgC6JWpU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = torch.load('/content/model-ppl_133.pt')"],"metadata":{"id":"go-HitNQV_R1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lr = 3\n","wd = 1e-6\n","optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=0.9)"],"metadata":{"id":"YVwLp-02JWpV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loss_train_hist = []\n","loss_valid_hist = []\n","\n","metric_train_hist = []\n","metric_valid_hist = []\n","\n","best_loss_valid = torch.inf\n","epoch_counter = 0"],"metadata":{"id":"zqxSVVB7JWpW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_epochs = 30\n","\n","for epoch in range(1, num_epochs+1):\n","  # WandB\n","  run = wandb.init(\n","        project=\"language-modeling-lstms\",\n","        config={\n","            \"learning_rate\": lr,\n","            \"epochs\": num_epochs,\n","        })\n","\n","  # Train\n","  model, loss_train, metric_train = train_one_epoch(model,\n","                                                    train_loader,\n","                                                    loss_fn,\n","                                                    optimizer,\n","                                                    metric,\n","                                                    epoch)\n","  # Validation\n","  loss_valid, metric_valid = evaluate(model,\n","                                      valid_loader,\n","                                      loss_fn,\n","                                      metric)\n","\n","  loss_train_hist.append(loss_train)\n","  loss_valid_hist.append(loss_valid)\n","\n","  metric_train_hist.append(metric_train)\n","  metric_valid_hist.append(metric_valid)\n","\n","  if loss_valid < best_loss_valid:\n","    torch.save(model, f'model.pt')\n","    best_loss_valid = loss_valid\n","    print('Model Saved!')\n","\n","  print(f'Valid: Loss = {loss_valid:.4}, Metric = {metric_valid:.4}')\n","  print()\n","\n","  epoch_counter += 1"],"metadata":{"id":"eVqS9SEPJWpW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## üü† Main Loop"],"metadata":{"id":"rjGQ-M02cusP"}},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"jsWyc30h3mef","executionInfo":{"status":"ok","timestamp":1726603275882,"user_tz":-210,"elapsed":1019,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["set_seed(seed)\n","train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)"],"metadata":{"id":"uF3H9DeD6TCn","executionInfo":{"status":"ok","timestamp":1726603283001,"user_tz":-210,"elapsed":661,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["len(vocab)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0MwVqDwt6o56","executionInfo":{"status":"ok","timestamp":1726609006219,"user_tz":-210,"elapsed":1067,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}},"outputId":"75020b85-2e7c-457d-a85c-6321ca0a4df0"},"execution_count":58,"outputs":[{"output_type":"execute_result","data":{"text/plain":["28782"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":["set_seed(seed)\n","\n","model = LanguageModel(vocab_size=len(vocab), embedding_dim=embedding_dim,\n","                      hidden_dim=hidden_dim, num_layers=num_layers,\n","                      dropoute=dropoute, dropouti=dropouti,\n","                      dropouth=dropouth, dropouto=dropouto,\n","                      weight_drop=weight_drop).to(device)\n","model"],"metadata":{"id":"JCtZXDybxexf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726603294559,"user_tz":-210,"elapsed":639,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}},"outputId":"239846a6-e6dc-425d-8eac-f861ba770704"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Applying weight drop of 0.5 to weight_hh_l0\n","Applying weight drop of 0.5 to weight_hh_l0\n","Applying weight drop of 0.5 to weight_hh_l0\n"]},{"output_type":"execute_result","data":{"text/plain":["LanguageModel(\n","  (embedding): Embedding(28782, 300)\n","  (lstms): ModuleList(\n","    (0): WeightDrop(\n","      (module): LSTM(300, 1150)\n","    )\n","    (1): WeightDrop(\n","      (module): LSTM(1150, 1150)\n","    )\n","    (2): WeightDrop(\n","      (module): LSTM(1150, 300)\n","    )\n","  )\n","  (fc): Linear(in_features=300, out_features=28782, bias=True)\n","  (lockdrop): LockedDropout()\n",")"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["# model = torch.load('model.pt')"],"metadata":{"id":"Klf6g_N8c-Ub"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["üî∞ Define optimizer and Set learning rate and weight decay."],"metadata":{"id":"AUKZRiQPxqrB"}},{"cell_type":"code","source":["set_seed(seed)\n","\n","lr = 7.5\n","wd = 1.2e-6\n","# momentum = 0.9\n","\n","optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=momentum)\n","# optimizer = optim.SGD([{'params': model.embedding.parameters(), 'lr': 0.1*lr},\n","#                        {'params': model.lstms.parameters(), 'lr': lr}],\n","#                       weight_decay=wd, momentum=momentum)\n","optimizer"],"metadata":{"id":"bowjVB5yIXUP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1726608046354,"user_tz":-210,"elapsed":654,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}},"outputId":"8f2a0ce8-e11d-40c5-a8a1-b0f8547d1e86"},"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SGD (\n","Parameter Group 0\n","    dampening: 0\n","    differentiable: False\n","    foreach: None\n","    fused: None\n","    lr: 7.5\n","    maximize: False\n","    momentum: 0\n","    nesterov: False\n","    weight_decay: 1.2e-06\n",")"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":["if wandb_enable:\n","  wandb.init(\n","      project='LM-AWD-LSTM',\n","      name=wandb_arg_name,\n","      config={\n","          'lr': lr,\n","          'momentum': momentum,\n","          'batch_size': batch_size,\n","          'seq_len': seq_len,\n","          'hidden_dim': hidden_dim,\n","          'embedding_dim': embedding_dim,\n","          'num_layers': num_layers,\n","          'dropout_embed': dropoute,\n","          'dropout_in_lstm': dropouti,\n","          'dropout_h_lstm': dropouth,\n","          'dropout_out_lstm': dropouto,\n","          'clip': clip,\n","      }\n","  )"],"metadata":{"id":"0yboUzafnGD8","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1726608287797,"user_tz":-210,"elapsed":3906,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}},"outputId":"76f9f08f-4b01-442d-f92b-2507b26bb1d0"},"execution_count":55,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.18.1"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20240917_212443-3dwaq08b</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/amirmahdiaramideh-university-of-guilan/LM-AWD-LSTM/runs/3dwaq08b' target=\"_blank\">weight_drop</a></strong> to <a href='https://wandb.ai/amirmahdiaramideh-university-of-guilan/LM-AWD-LSTM' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/amirmahdiaramideh-university-of-guilan/LM-AWD-LSTM' target=\"_blank\">https://wandb.ai/amirmahdiaramideh-university-of-guilan/LM-AWD-LSTM</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/amirmahdiaramideh-university-of-guilan/LM-AWD-LSTM/runs/3dwaq08b' target=\"_blank\">https://wandb.ai/amirmahdiaramideh-university-of-guilan/LM-AWD-LSTM/runs/3dwaq08b</a>"]},"metadata":{}}]},{"cell_type":"markdown","source":["üî∞ Write code to train the model for `num_epochs` epoches."],"metadata":{"id":"AUyFFIzlyaiB"}},{"cell_type":"code","source":["loss_train_hist = []\n","loss_valid_hist = []\n","\n","metric_train_hist = []\n","metric_valid_hist = []\n","\n","best_loss_valid = torch.inf\n","epoch_counter = 0"],"metadata":{"id":"CAXagB4yvtZd","executionInfo":{"status":"ok","timestamp":1726603331032,"user_tz":-210,"elapsed":1778,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["set_seed(seed)\n","num_epochs = 5\n","\n","for epoch in range(1, num_epochs+1):\n","  # Train\n","  model, loss_train, metric_train = train_one_epoch(model,\n","                                                    train_loader,\n","                                                    loss_fn,\n","                                                    optimizer,\n","                                                    metric,\n","                                                    epoch)\n","  # Validation\n","  loss_valid, metric_valid = evaluate(model,\n","                                      valid_loader,\n","                                      loss_fn,\n","                                      metric)\n","\n","  loss_train_hist.append(loss_train)\n","  loss_valid_hist.append(loss_valid)\n","\n","  metric_train_hist.append(metric_train)\n","  metric_valid_hist.append(metric_valid)\n","\n","  if loss_valid < best_loss_valid:\n","    torch.save(model, f'model.pt')\n","    best_loss_valid = loss_valid\n","    print('Model Saved!')\n","\n","  print(f'Valid: Loss = {loss_valid:.4}, Metric = {metric_valid:.4}')\n","  print()\n","\n","  if wandb_enable:\n","    wandb.log({\"metric_train\": metric_train, \"loss_train\": loss_train,\n","                \"metric_valid\": metric_valid, \"loss_valid\": loss_valid})\n","\n","  epoch_counter += 1"],"metadata":{"id":"PovABWnU3ld0","colab":{"base_uri":"https://localhost:8080/","height":394},"outputId":"cdc5d841-5540-4102-e0c3-132288a1a9ad","executionInfo":{"status":"error","timestamp":1726608446386,"user_tz":-210,"elapsed":153573,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}}},"execution_count":56,"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 367/367 [02:13<00:00,  2.75batch/s, loss=4.16, metric=64.4]\n"]},{"output_type":"stream","name":"stdout","text":["Valid: Loss = 4.816, Metric = 124.1\n","\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2:  11%|‚ñà         | 41/367 [00:15<02:01,  2.68batch/s, loss=4.34, metric=77]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-56-be6d243dc06f>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   model, loss_train, metric_train = train_one_epoch(model,\n\u001b[0m\u001b[1;32m      7\u001b[0m                                                     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                                     \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-37-e35953940481>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, train_loader, loss_fn, optimizer, metric, epoch)\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m       \u001b[0mloss_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m       \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["wandb.finish()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":137},"id":"JDKmOvCY2AYX","executionInfo":{"status":"ok","timestamp":1695855403985,"user_tz":-210,"elapsed":3534,"user":{"displayName":"Howsam AI","userId":"14680048223925681202"}},"outputId":"1177c90d-5626-414f-afd2-d76728e3727c"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    body {\n","      font-size: 24px;\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">weight-drop</strong> at: <a href='https://wandb.ai/howsam/LM-AWD-LSTM/runs/g9ybeitf' target=\"_blank\">https://wandb.ai/howsam/LM-AWD-LSTM/runs/g9ybeitf</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230927_225610-g9ybeitf/logs</code>"]},"metadata":{}}]},{"cell_type":"code","source":["! cp /content/model.pt /content/drive/MyDrive/Deep_learning_projects/1_language_modeling/AWD"],"metadata":{"id":"lzUsHYFa03DC","executionInfo":{"status":"ok","timestamp":1726608451875,"user_tz":-210,"elapsed":1582,"user":{"displayName":"Amirmahdi Aramideh","userId":"05575284678348256491"}}},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":["## üü† Plot"],"metadata":{"id":"oK20iNRI3Xxb"}},{"cell_type":"markdown","source":["üî∞ Plot learning curves"],"metadata":{"id":"IKlLvCwuzEAA"}},{"cell_type":"code","source":["plt.figure(figsize=(8, 6))\n","\n","plt.plot(range(epoch_counter), loss_train_hist, 'r-', label='Train')\n","plt.plot(range(epoch_counter), loss_valid_hist, 'b-', label='Validation')\n","\n","plt.xlabel('Epoch')\n","plt.ylabel('loss')\n","plt.grid(True)\n","plt.legend()"],"metadata":{"id":"KYFzTsdIOkVp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# üî¥ **Test**"],"metadata":{"id":"KZ9UIdmkfxlA"}},{"cell_type":"markdown","source":["üî∞ Test your model using data from the test set and images that are not present in the dataset."],"metadata":{"id":"SO8iPWH1zVYn"}},{"cell_type":"code","source":["model_path = 'model.pt'\n","model = torch.load(model_path)\n","model.eval()"],"metadata":{"id":"09Q1Cwaa6sGb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loss_valid, metric_valid = evaluate(model, valid_loader, loss_fn, metric)\n","metric_valid"],"metadata":{"id":"_dgtH46XBWPF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loss_test, metric_test = evaluate(model, test_loader, loss_fn, metric)\n","metric_test"],"metadata":{"id":"35sn67IhKcm_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# üî¥ **Generate**"],"metadata":{"id":"FzcQQwFuar_7"}},{"cell_type":"markdown","source":["üî∞ Your mission is to write a `generate` function and use a desired sentence to evaluate the model"],"metadata":{"id":"jh2_9jUp0GF4"}},{"cell_type":"code","source":["model_path = 'model.pt'\n","model = torch.load(model_path)\n","model.eval()"],"metadata":{"id":"pskvb--R-wJ0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt = 'In a galaxy far, far away, there'\n","\n","indices = vocab(tokenizer(prompt))\n","itos = vocab.get_itos()\n","\n","max_seq_len = 35\n","for i in range(max_seq_len):\n","  src = torch.LongTensor(indices).to(device)\n","\n","  with torch.no_grad():\n","    prediction = model(src)\n","\n","  # Method 1\n","  # idx = torch.argmax(prediction[-1])\n","  # itos = vocab.get_itos()\n","  # itos[idx]\n","\n","  # Method 2\n","  temperature = 0.5\n","  probs = torch.softmax(prediction[-1]/temperature, dim=0)\n","\n","  idx = vocab['<ukn>']\n","  while idx == vocab['<ukn>']:\n","    idx = torch.multinomial(probs, num_samples=1).item()\n","\n","  token = itos[idx]\n","  prompt += ' ' + token\n","\n","  if idx == vocab['.']:\n","    break\n","\n","  indices.append(idx)\n","\n","print(prompt)"],"metadata":{"id":"PsTQu0p6RsgO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate(prompt, max_seq_len, temperature, model, tokenizer, vocab, seed=None):\n","  if seed is not None:\n","    torch.manual_seed(seed)\n","\n","  indices = vocab(tokenizer(prompt))\n","  itos = vocab.get_itos()\n","\n","  for i in range(max_seq_len):\n","    src = torch.LongTensor(indices).to(device)\n","\n","    with torch.no_grad():\n","      prediction = model(src)\n","\n","    # Method 1\n","    # idx = torch.argmax(prediction[-1])\n","    # itos = vocab.get_itos()\n","    # itos[idx]\n","\n","    # Method 2\n","    probs = torch.softmax(prediction[-1]/temperature, dim=0)\n","\n","    idx = vocab['<ukn>']\n","    while idx == vocab['<ukn>']:\n","      idx = torch.multinomial(probs, num_samples=1).item()\n","\n","    token = itos[idx]\n","    prompt += ' ' + token\n","\n","    if idx == vocab['.']:\n","      return prompt\n","\n","    indices.append(idx)\n","\n","  return prompt"],"metadata":{"id":"f5SvSDLal8YB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt = 'In a galaxy far, far away, there'\n","prompt = 'The sun was setting in the'\n","prompt = 'Once upon a time, there lived a young princess named'\n","prompt = 'What is the meaning '\n","\n","generate(prompt, 35, 0.5, model, tokenizer, vocab)"],"metadata":{"id":"v_Cw2bzfRmY9"},"execution_count":null,"outputs":[]}]}